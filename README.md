# ğŸ§  RAG-BOT: Multi-PDF Knowledge Chatbot by Amon

> **Built With**: FastAPI âš¡ | LangChain ğŸ§  | React.js âš›ï¸ | Datastax Astra DB ğŸš€ | Supabase PostgreSQL ğŸ—ƒï¸ | Meta-Llama 4 Maverick 17B Model ğŸ¦™ | Together AI

---

## ğŸ“š Overview

RAG-BOT is an advanced **Retrieval Augmented Generation (RAG)** chatbot that allows users to upload **multiple PDFs**, **ask complex questions**, and receive **smart, contextual answers**.

It is **full-stack**, **scalable**, **vector-database driven**, and **ready for production**!

---

## ğŸ›  Tech Stack

| Layer | Technology |
|:---|:---|
| Backend | FastAPI (Python) |
| NLP Engine | LangChain |
| Model | Meta-Llama 4 Maverick 17B 128E FP8 |
| Vector Storage | Datastax Astra DB |
| SQL Storage | Supabase PostgreSQL |
| Frontend | Next.js (React + TypeScript) |
| Temp Storage | Local Server Filesystem (for processing uploads) |

---

## âš¡ï¸ Features

- âœ… Upload **multiple** PDFs.
- âœ… Intelligent document **chunking and embedding**.
- âœ… Context-aware **question understanding** (structured parsing).
- âœ… **Section-based** retrieval: beginning, middle, end.
- âœ… **Contextual Prompt Engineering** (custom RAG prompt).
- âœ… Built-in **JWT Authentication** (Coming Soon ğŸ”’).
- âœ… **Dockerized** and **CI/CD ready**.
- âœ… Ultra-lightweight API for **easy frontend integration**.

---

## ğŸ“‚ Project Structure

```
/server
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ classes/        # Pydantic data classes (Question, Answer)
â”‚   â”œâ”€â”€ db/             # Database connections (Supabase, AstraDB)
â”‚   â”œâ”€â”€ langchain/
â”‚   â”‚   â”œâ”€â”€ initialize/ # Model, Embedding, Vector store initialization
â”‚   â”‚   â””â”€â”€ chatFlow.py # Core RAG business logic
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ chatRoute.py # API Endpoints
â”‚   â””â”€â”€ main.py          # FastAPI entrypoint
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## ğŸŒ API Endpoints

### POST `/chat/{id}`

#### â¡ï¸ Description:
Upload one or multiple PDFs and ask a natural language question.  
The system will parse, chunk, embed the documents, search for context, and answer.

#### ğŸ›ï¸ Request:
- **Path Parameter**: `id` â†’ Random chatId for session.
- **Body (multipart/form-data)**:
  | Field | Type | Description |
  |:---|:---|:---|
  | files | List of UploadFile (PDFs) | Required |
  | question | String | Required |

#### ğŸ§© Example cURL:
```bash
curl -X POST "http://127.0.0.1:8080/chat/123456" \
  -H "accept: application/json" \
  -F "question=What are the key findings of this report?" \
  -F "files=@/path/to/file1.pdf" \
  -F "files=@/path/to/file2.pdf"
```

#### ğŸ›ï¸ Response:
```json
{
  "question": "What are the key findings of this report?",
  "answer": "The key findings highlight the major contributions made by the project, divided across its beginning, middle, and concluding sections. Thanks for asking!"
}
```

---

## ğŸ›¡ Environment Variables

Create a `.env` file in `/server`:

```env
# Supabase PostgreSQL
DATABASE_URL=postgresql://postgres:password@host:port/postgres
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-supabase-service-role-key

# Datastax Astra VectorDB
ASTRA_NAMESPACE=default_keyspace
ASTRA_TOKEN=your-astra-token
ASTRA_ENDPOINT=https://your-region.apps.astra.datastax.com

# LangSmith (Optional for Observability)
LANGSMITH_API_KEY=your-langsmith-api-key
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_PROJECT=your-project

# Together AI / NVIDIA API Keys (optional future upgrades)
TOGETHER_API_KEY=your-together-ai-key
NVIDIA_API_KEY=your-nvidia-api-key
```

---

## ğŸ›  Setup (Local)

1. Clone the repo
```bash
git clone https://github.com/Amon20044/RAG_Backend.git
cd RAG_Backend/server
```

2. Create Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate
```

3. Install Requirements
```bash
pip install -r requirements.txt
```

4. Start Server
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8080
```

Open browser:  
ğŸ‘‰ http://127.0.0.1:8080/docs (Swagger UI auto-generated)

---

## ğŸ³ Docker Deployment

```bash
docker build -t rag-bot .
docker run -d -p 8080:8080 --name rag-bot-container rag-bot
```

Server will be running at:  
ğŸ‘‰ `http://127.0.0.1:8080`

---

## ğŸ§  Flow Diagram (System Architecture)

```plaintext
[Frontend (React.js)]
        â†“
  [FastAPI Server (Backend)]
        â†“
 [File Upload (Temp Storage)]
        â†“
 [Chunk & Embed (LangChain)]
        â†“
 [Vector DB (Astra DB)]
        â†“
 [Meta Llama 4 (Inference)]
        â†“
  [Return Answer to User]
```
![diagram-export-4-27-2025-6_17_11-AM](https://github.com/user-attachments/assets/bdbf28a6-b572-4a3f-bd85-77178a0d3a7c)


---

## ğŸš€ Future Work (Roadmap)

- [x] JWT Authentication Middleware for Protected Routes
- [x] Frontend: React.js + Tailwind UI Integration
- [x] Supabase PostgreSQL for storing metadata (user, chat history)
- [ ] Deploy on Railway or AWS EC2
- [ ] Multiple Model Switching (e.g., GPT-4, Claude, Llama)

---

## ğŸ¤ Acknowledgements

- [LangChain](https://github.com/langchain-ai/langchain)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Datastax Astra](https://www.datastax.com/astra)
- [Supabase](https://supabase.com/)
- [Meta AI (Llama-4 Maverick)](https://ai.meta.com/)

---

## âœ¨ Built with â¤ï¸ by [Amon Sharma](https://github.com/Amon20044)

> *"Learning every day. Building future today."* ğŸš€

---

# ğŸš€ **[Star ğŸŒŸ this Repo if you loved the project!]**
